{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Gather Data\n",
    "We want to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "data_dir_path = \"../data/\"\n",
    "# Read the csv files\n",
    "results = pd.read_csv(data_dir_path + \"results.csv\", na_values=np.nan)\n",
    "driver_standings = pd.read_csv(data_dir_path + \"driver_standings.csv\", na_values=np.nan)\n",
    "constructor_standings = pd.read_csv(\n",
    "    data_dir_path + \"constructor_standings.csv\", na_values=np.nan\n",
    ")\n",
    "raceYears = pd.read_csv(data_dir_path + \"races.csv\", na_values=np.nan)\n",
    "names = pd.read_csv(data_dir_path + \"drivers.csv\", na_values=np.nan)\n",
    "\n",
    "# Filter columns\n",
    "raceYears = raceYears[[\"raceId\", \"year\"]]\n",
    "# raceYears = raceYears[raceYears[\"year\"] >= 2010]  # Only data after 2010\n",
    "results = results[[\"raceId\", \"driverId\", \"constructorId\", \"grid\", \"position\"]]\n",
    "driver_standings = driver_standings[[\"raceId\", \"driverId\", \"position\"]]\n",
    "constructor_standings = constructor_standings[[\"raceId\", \"constructorId\", \"position\"]]\n",
    "names = names[[\"driverId\", \"driverRef\"]]\n",
    "\n",
    "# rename because other csv also have position\n",
    "driver_standings = driver_standings.rename(columns={\"position\": \"driverStanding\"})\n",
    "constructor_standings = constructor_standings.rename(\n",
    "    columns={\"position\": \"constructorStanding\"}\n",
    ")\n",
    "\n",
    "year_driver_standing = pd.merge(raceYears, driver_standings, on=[\"raceId\"], how=\"inner\")\n",
    "\n",
    "results_driver_standings = pd.merge(\n",
    "    results, year_driver_standing, on=[\"raceId\", \"driverId\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "joined_data = pd.merge(\n",
    "    results_driver_standings,\n",
    "    constructor_standings,\n",
    "    on=[\"raceId\", \"constructorId\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "joined_data = pd.merge(joined_data, names, on=[\"driverId\"], how=\"inner\")\n",
    "joined_data.drop(columns=[\"raceId\", \"constructorId\", \"driverId\"], inplace=True)\n",
    "joined_data.replace(to_replace=\"\\\\N\", value=20, inplace=True)\n",
    "joined_data[\"position\"] = joined_data[\"position\"].astype(int)\n",
    "\n",
    "# Drop year before calculating the mean for every driver\n",
    "joined_data.drop(\"year\", axis=1)\n",
    "\n",
    "X = joined_data[[\"grid\", \"driverStanding\", \"constructorStanding\"]]\n",
    "Y = joined_data[[\"position\"]]\n",
    "\n",
    "\n",
    "# Divide by train data and test data\n",
    "# train_data = joined_data.loc[joined_data[\"year\"] <= 2000]\n",
    "# test_data = joined_data.loc[joined_data[\"year\"] > 2000]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# Calculate mean values for every driver\n",
    "# train_data = train_data.groupby([\"driverRef\"]).mean()\n",
    "# test_data = test_data.groupby([\"driverRef\"]).mean()\n",
    "\n",
    "# X_train = train_data[[\"grid\", \"driverStanding\", \"constructorStanding\"]]\n",
    "# Y_train = train_data[[\"position\"]]\n",
    "\n",
    "# X_test = train_data[[\"grid\", \"driverStanding\", \"constructorStanding\"]]\n",
    "# Y_test = train_data[[\"position\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def edit_Y(y, regression=True):\n",
    "    \"\"\"Edits Y to be 1 or not 1 for regression or not regression.\n",
    "\n",
    "    Notes:\n",
    "        Pandas DF is passed by reference, so no returns.\n",
    "\n",
    "    Args:\n",
    "        y (pd.DataFrame): Dataframe with column position\n",
    "        regression (bool, optional): True if regression, false for others.\n",
    "    \"\"\"\n",
    "    y.loc[(y[\"position\"] != 1) & (y[\"position\"] != 2) & (y[\"position\"] != 3)] = (\n",
    "        0 if regression else -1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "edit_Y(Y_train, regression=True)\n",
    "edit_Y(Y_test, regression=True)\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "\n",
    "Y_train = Y_train.reshape(Y_train.shape[0])\n",
    "Y_test = Y_test.reshape(Y_test.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Standardise and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "def plot_error(training_error, testing_error):\n",
    "    \"\"\"Plots the training and testing error.\n",
    "\n",
    "    Args:\n",
    "        training_error (list): List of training errors\n",
    "        testing_error (list): List of testing errors\n",
    "    \"\"\"\n",
    "    plt.plot(training_error, label=\"Training Error\")\n",
    "    plt.plot(testing_error, label=\"Testing Error\")\n",
    "    plt.xticks(np.arange(len(testing_error)), np.arange(1, len(testing_error) + 1))\n",
    "    plt.xlabel(\"Degree\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy(training_acc, testing_acc):\n",
    "    \"\"\"Plots the training and testing error.\n",
    "\n",
    "    Args:\n",
    "        training_error (list): List of training errors\n",
    "        testing_error (list): List of testing errors\n",
    "    \"\"\"\n",
    "    plt.plot(training_acc, label=\"Training Accuracy\")\n",
    "    plt.plot(testing_acc, label=\"Testing Accuracy\")\n",
    "    plt.xticks(np.arange(len(testing_acc)), np.arange(1, len(testing_acc) + 1))\n",
    "    plt.xlabel(\"Degree\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot(training_error, testing_error, training_acc, testing_acc):\n",
    "    plot_error(training_error, testing_error)\n",
    "    plot_accuracy(training_acc, testing_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4A Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def polynomial_logistic_regression(X_train, Y_train, X_test, Y_test, max_degree=6):\n",
    "    \"\"\"Polynomial logistic regression\n",
    "\n",
    "    Args:\n",
    "        X_train (np.array): Training data\n",
    "        Y_train (np.array): Training labels\n",
    "        X_test (np.array): Testing data\n",
    "        Y_test (np.array): Testing labels\n",
    "    \"\"\"\n",
    "    logreg = LogisticRegression(multi_class=\"multinomial\", max_iter=10_000)\n",
    "    training_error, testing_error = [], []\n",
    "    training_acc, testing_acc = [], []\n",
    "\n",
    "    print(\"Polynomial Logistic Regression Score\")\n",
    "    print(\"Degree \\t Test Score \\t Train Score\")\n",
    "    for i in range(1, max_degree + 1):\n",
    "        # Init polynomial features\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "\n",
    "        # Polynomial fit of training data\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "        # Train model\n",
    "        logreg.fit(X_train_poly, Y_train)\n",
    "\n",
    "        # Polynomial fit of test data\n",
    "        X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "        # Get scores\n",
    "        training_score = logreg.score(X_train_poly, Y_train)\n",
    "        testing_score = logreg.score(X_test_poly, Y_test)\n",
    "\n",
    "        # Append accuracy\n",
    "        training_acc.append(training_score)\n",
    "        testing_acc.append(testing_score)\n",
    "\n",
    "        # Append errors\n",
    "        training_error.append(1 - training_score)\n",
    "        testing_error.append(1 - testing_score)\n",
    "\n",
    "        # Fancy print B)\n",
    "        print(f\"{i} \\t {testing_score*100.0:.2f}% \\t {training_score*100.0:.2f}%\")\n",
    "\n",
    "    return training_error, testing_error, training_acc, testing_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    training_error,\n",
    "    testing_error,\n",
    "    training_acc,\n",
    "    testing_acc,\n",
    ") = polynomial_logistic_regression(X_train, Y_train, X_test, Y_test, max_degree=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "plot(training_error, testing_error, training_acc, testing_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4B SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# svmachine = SVC(kernel='rbf', C=1E6)\n",
    "# svmachine.fit(X_train, Y_train)\n",
    "# svmachine.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# svmachine.score(X_test, Y_test)\n",
    "# svmachine2 = SVC(kernel=\"poly\", degree=7)\n",
    "# svmachine2.fit(X_train, Y_train)\n",
    "# svmachine2.score(X_train, Y_train)\n",
    "# svmachine2.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def polynomial_svm(X_train, Y_train, X_test, Y_test, max_degree=6):\n",
    "    \"\"\"Polynomial Support Vector Machine\n",
    "\n",
    "    Args:\n",
    "        X_train (np.array): Training data\n",
    "        Y_train (np.array): Training labels\n",
    "        X_test (np.array): Testing data\n",
    "        Y_test (np.array): Testing labels\n",
    "    \"\"\"\n",
    "    training_error, testing_error = [], []\n",
    "    training_acc, testing_acc = [], []\n",
    "\n",
    "    print(\"Polynomial SVM Score\")\n",
    "    print(\"Degree \\t Test Score \\t Train Score\")\n",
    "    for i in range(1, max_degree + 1):\n",
    "        svmachine = SVC(kernel=\"poly\", degree=i)\n",
    "\n",
    "        # Init polynomial features\n",
    "        # poly = PolynomialFeatures(degree=i)\n",
    "\n",
    "        # # Polynomial fit of training data\n",
    "        # X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "        # X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "        svmachine.fit(X_train, Y_train)\n",
    "        # Get scores\n",
    "        training_score = svmachine.score(X_train, Y_train)\n",
    "        testing_score = svmachine.score(X_test, Y_test)\n",
    "\n",
    "        # Append accuracy\n",
    "        training_acc.append(training_score)\n",
    "        testing_acc.append(testing_score)\n",
    "\n",
    "        # Append errors\n",
    "        training_error.append(1 - training_score)\n",
    "        testing_error.append(1 - testing_score)\n",
    "\n",
    "        # Fancy print B)\n",
    "        print(f\"{i} \\t {testing_score*100.0:.2f}% \\t {training_score*100.0:.2f}%\")\n",
    "\n",
    "    return training_error, testing_error, training_acc, testing_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "training_error, testing_error, training_acc, testing_acc = polynomial_svm(\n",
    "    X_train, Y_train, X_test, Y_test, max_degree=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "plot(training_error, testing_error, training_acc, testing_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
